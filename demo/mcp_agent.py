import asyncio
import json
import os
import sys
import re  # [í•„ìˆ˜] ì •ê·œí‘œí˜„ì‹ ëª¨ë“ˆ
from typing import List, Dict, Any

from openai import AsyncOpenAI
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# -----------------------------------------------------------------------------
# 1. ì„¤ì • (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
# -----------------------------------------------------------------------------
SGLANG_API_URL = "http://localhost:30000/v1"
MODEL_NAME = "default"  # SGLang ë¡œë“œ ëª¨ë¸ (ë³´í†µ default)
MCP_SERVER_SCRIPT = "mcp_server_standalone.py"  # ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨

# -----------------------------------------------------------------------------
# 2. ë„êµ¬ ì •ì˜ (Qwenì—ê²Œ ë³´ì—¬ì¤„ ë©”ë‰´íŒ - Docstringê³¼ ì¼ì¹˜ì‹œí‚´)
# -----------------------------------------------------------------------------
TOOLS_SCHEMA = [
    {
        "type": "function",
        "function": {
            "name": "list_modis_images",
            "description": "[CRITICAL STEP 1] Retrieve a list of already generated/cached MODIS images. ALWAYS call this FIRST.",
            "parameters": {"type": "object", "properties": {}, "required": []}
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_modis_image",
            "description": "[STEP 2-A] Retrieve image data for a specific filename found in list.",
            "parameters": {
                "type": "object",
                "properties": {"filename": {"type": "string"}},
                "required": ["filename"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "fetch_modis_data",
            "description": "[STEP 2-B] Fetch NEW MODIS imagery. WARNING: SLOW. Use only if image not in list.",
            "parameters": {
                "type": "object",
                "properties": {
                    "date_str": {"type": "string", "description": "YYYY-MM-DD"},
                    "satellite": {"type": "string", "enum": ["terra", "aqua"]},
                    "west": {"type": "number"}, "south": {"type": "number"},
                    "east": {"type": "number"}, "north": {"type": "number"},
                    "is_daytime": {"type": "boolean"},
                    "pinpoint_lat": {"type": "number"}, "pinpoint_lng": {"type": "number"}
                },
                "required": ["date_str", "satellite", "west", "south", "east", "north"]
            }
        }
    }
]

# -----------------------------------------------------------------------------
# 3. í•µì‹¬ ë¶„ì„ í”„ë¡¬í”„íŠ¸ (ì´ë¯¸ì§€ ì£¼ì… ì‹œì ì— ì‚¬ìš©)
# -----------------------------------------------------------------------------
FINAL_ANALYSIS_INSTRUCTION = """
## Role & Task
You are an expert meteorologist. The requested satellite imagery has been retrieved.
Your task is to synthesize a comprehensive analysis based on this visual data.

## Instructions
1. **Analyze** the provided MODIS satellite image (RGB + LST with purple dot).
2. **Think step-by-step** about the observation.
3. **Wrap your thinking process** in <think></think> tags.
4. **Final Output:** Provide a unified, professional weather report (6-10 sentences).
5. **Focus** on the most important findings and their implications.
6. **Create a cohesive narrative** that directly addresses the user's original question.
"""

# -----------------------------------------------------------------------------
# 4. Mock Classes for Manual Parsing (SGLang í˜¸í™˜ì„± íŒ¨ì¹˜ìš©)
# -----------------------------------------------------------------------------
class MockFunction:
    def __init__(self, name, arguments):
        self.name = name
        # ì¸ìê°€ ì´ë¯¸ dictë¼ë©´ stringìœ¼ë¡œ ë³€í™˜, stringì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        self.arguments = json.dumps(arguments) if isinstance(arguments, dict) else arguments

class MockToolCall:
    def __init__(self, name, arguments):
        self.id = f"call_{name}_{os.urandom(4).hex()}"
        self.type = "function"
        self.function = MockFunction(name, arguments)

# -----------------------------------------------------------------------------
# 5. ë©”ì¸ íŒŒì´í”„ë¼ì¸ (MCP Host Implementation)
# -----------------------------------------------------------------------------
async def run_vlm_agent_loop(user_query: str, system_prompt: str):
    client = AsyncOpenAI(base_url=SGLANG_API_URL, api_key="EMPTY")

    # MCP ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì„¤ì •
    server_params = StdioServerParameters(
        command=sys.executable,
        args=[MCP_SERVER_SCRIPT],
        env=os.environ.copy()
    )

    print(f"ğŸ”Œ Connecting to MCP Server: {MCP_SERVER_SCRIPT}...")
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query}
            ]

            print(f"\nğŸ’¬ User Query: {user_query}")

            for turn in range(3):
                print(f"\n--- Turn {turn + 1} (Thinking...) ---")
                
                response = await client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=messages,
                    tools=TOOLS_SCHEMA,
                    tool_choice="auto",
                    temperature=0.1
                )
                
                msg = response.choices[0].message
                content = msg.content or ""


                if not msg.tool_calls:
                    # 1. <tool_call> íƒœê·¸ í™•ì¸
                    if "<tool_call>" in content:
                        print("âš ï¸  Detected raw <tool_call> in text. Parsing manually...")
                        try:
                            # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ íƒœê·¸ ì•ˆì˜ JSON ë‚´ìš© ì¶”ì¶œ
                            pattern = r"<tool_call>(.*?)</tool_call>"
                            matches = re.findall(pattern, content, re.DOTALL)
                            
                            if matches:
                                msg.tool_calls = []
                                for match in matches:
                                    # JSON íŒŒì‹±
                                    tool_json = json.loads(match.strip())
                                    
                                    # nameê³¼ argumentsê°€ ìˆëŠ”ì§€ í™•ì¸
                                    if "name" in tool_json and "arguments" in tool_json:
                                        msg.tool_calls.append(
                                            MockToolCall(tool_json["name"], tool_json["arguments"])
                                        )
                                    else:
                                        print(f"âŒ Invalid tool call format: {tool_json}")

                        except Exception as e:
                            print(f"âŒ Manual parsing failed: {e}")
                            print(f"   Content was: {content}")

                # =================================================================

                # ì—¬ì „íˆ ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ -> ì§„ì§œ ë‹µë³€ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ì¢…ë£Œ
                if not msg.tool_calls:
                    print(f"ğŸ¤– Final Answer:\n{msg.content}")
                    return

                # ë„êµ¬ í˜¸ì¶œ ë¡œì§ ì§„í–‰
                if isinstance(msg.tool_calls[0], MockToolCall):
                    # Mock ê°ì²´ì¸ ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ dict êµ¬ì„±í•˜ì—¬ ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€
                    tool_calls_dict = [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in msg.tool_calls
                    ]
                    messages.append({
                        "role": "assistant",
                        "content": content, # ì›ë³¸ í…ìŠ¤íŠ¸(<tool_call> í¬í•¨) ìœ ì§€
                        "tool_calls": tool_calls_dict
                    })
                else:
                    # ì •ìƒì ì¸ OpenAI ê°ì²´ë¼ë©´ ê·¸ëŒ€ë¡œ append
                    messages.append(msg)
                
                # ë„êµ¬ ì‹¤í–‰
                for tool_call in msg.tool_calls:
                    fn_name = tool_call.function.name
                    fn_args = json.loads(tool_call.function.arguments)
                    
                    print(f"ğŸ› ï¸  Model calls: {fn_name}")
                    print(f"    Args: {fn_args}")

                    # MCP ì„œë²„ì— ì‹¤í–‰ ìš”ì²­
                    result = await session.call_tool(fn_name, arguments=fn_args)
                    
                    # ê²°ê³¼ íŒŒì‹±
                    output_text = ""
                    output_data = {}
                    
                    # MCP SDK ì‘ë‹µ êµ¬ì¡° ì²˜ë¦¬
                    for content_item in result.content:
                        if hasattr(content_item, "text"):
                            output_text += content_item.text
                            try:
                                output_data = json.loads(content_item.text)
                            except:
                                pass

                    # -------------------------------------------------------
                    # [í•µì‹¬] ì´ë¯¸ì§€ê°€ ë°œê²¬ë˜ë©´ í”„ë¡¬í”„íŠ¸ ì£¼ì… ë° íƒœì„¸ ì „í™˜
                    # -------------------------------------------------------
                    if output_data.get("success") and "data_uri" in output_data:
                        print("ğŸ–¼ï¸  Image retrieved! Injecting image & specific analysis prompt...")
                        
                        # 1. Tool ê²°ê³¼ ë©”ì‹œì§€ (ì„±ê³µ ê¸°ë¡)
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": "Image fetched successfully."
                        })

                        # 2. ì´ë¯¸ì§€ + ì „ë¬¸ê°€ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì£¼ì…
                        image_msg = {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text", 
                                    "text": f"Here is the satellite image.\n\n{FINAL_ANALYSIS_INSTRUCTION}"
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {"url": output_data["data_uri"]}
                                }
                            ]
                        }
                        messages.append(image_msg)
                        
                        # ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìœ¼ë¯€ë¡œ ë‹¤ìŒ í„´(ë¶„ì„)ìœ¼ë¡œ ë°”ë¡œ ë„˜ê¹€
                        break 
                    
                    else:
                        # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ì¼ë°˜ ì‘ë‹µ
                        print(f"âœ… Result: {output_text[:100]}...")
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": output_text
                        })

# -----------------------------------------------------------------------------
# 6. ì‹¤í–‰
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    # ì§ˆë¬¸ ì˜ˆì‹œ
    query = """
    Analyze the MODIS terra daytime satellite imagery for California on August 15, 2023. (west:-124, south:32.5, east:-114, north:42)
    """

    
    # ì´ˆê¸° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” ê°€ë³ê²Œ ì„¤ì •
    sys_prompt = "You are a helpful meteorologist AI. Use tools to fetch satellite imagery when needed. Always check existing images first."

    try:
        asyncio.run(run_vlm_agent_loop(query, sys_prompt))
    except KeyboardInterrupt:
        print("\nStopped by user.")
    except Exception as e:
        print(f"\nError: {e}")
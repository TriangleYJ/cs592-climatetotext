{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observation_coord = \"active_stations_lat_lon.csv\"\n",
    "annotation = \"generated_weather_dataset_gemini.jsonl\"\n",
    "ir_images=\"./ir\"\n",
    "rgb_images=\"./rgb\"\n",
    "\n",
    "# active_stations_lat_lon.csv sample line\n",
    "\"\"\"\n",
    "id,latitude,longitude\n",
    "00FAY,53.19,-112.25\n",
    "\"\"\"\n",
    "# generated_weather_dataset_gemini.jsonl sample line\n",
    "\"\"\"\n",
    "{\"sample_id\": \"65344\", \"source_filename\": \"65344_terra_day_coco25_23100311_lh11_5.093901_0.147878_14.319126_9.507087.png\", \"ground_truth_labels\": {\"id\": \"65344\", \"time\": \"2023-10-03 11:00:00\", \"lat\": 6.35, \"lon\": 2.3833, \"coco\": 25, \"local_hour\": 11, \"temp\": 28.4, \"dwpt\": 24.6, \"rhum\": 80.0, \"prcp\": 0.1, \"snow\": NaN, \"wdir\": 223.0, \"wspd\": 14.8, \"wpgt\": NaN, \"pres\": 1011.9, \"tsun\": NaN, \"filename\": \"65344_terra_day_coco25_23100311_lh11_5.093901_0.147878_14.319126_9.507087.png\", \"satellite\": \"terra\", \"day_night\": \"day\", \"utc_yymmddhh\": \"23100311\", \"local_hour_filename\": 11, \"bbox_lat1\": 5.093901, \"bbox_lon1\": 0.147878, \"bbox_lat2\": 14.319126, \"bbox_lon2\": 9.507087}, \"generated_qas\": [{\"theme\": \"Theme 0: Basic Observation\", \"question\": \"Describe the weather conditions in the observation region based on the images provided.\", \"answer\": \"The observation region is dominated by highly unstable weather, characterized by intense, vertically developed cloud masses. The RGB image shows very bright, towering cumuliform clouds, indicative of deep convection, which suggests conditions conducive to heavy rain and strong winds. The LST/IR panel is largely black across the cloudy regions, confirming the presence of very high-altitude, cold cloud tops associated with mature convective cells, typical of an active storm environment.\"}, {\"theme\": \"Theme 1: Holistic Analysis\", \"question\": \"What is the overall synoptic situation indicated by the cloud structures visible across this region?\", \"answer\": \"The overall synoptic situation suggests a highly unstable atmosphere characterized by widespread deep moist convection. The presence of numerous, massive cumulonimbus clouds, highly reflective in the visible spectrum, points to strong uplift and significant latent heat release. This pattern is characteristic of a highly energetic environment where moisture and instability fuel organized storm development across a broad area, often leading to thunderstorms.\"}, {\"theme\": \"Theme 2: Qualitative Inference\", \"question\": \"Based on the appearance of the cloud structures, what qualitative assessment can be made regarding the wind intensity associated with this system?\", \"answer\": \"The visual evidence suggests that the wind intensity, particularly associated with the storm dynamics, is qualitatively high. The turbulent, rapidly developing nature of the towering convective cells in the RGB image indicates strong vertical wind shear and significant horizontal winds feeding the storm system. High wind speeds are necessary to maintain the vigorous uplift and deep structure seen in these powerful convective clouds.\"}, {\"theme\": \"Theme 3: Causal Reasoning\", \"question\": \"What primary meteorological factors are likely causing the formation and rapid growth of these large, vertically developed convective clouds?\", \"answer\": \"The primary cause of this intense cloud formation is a combination of atmospheric instability and abundant moisture. The towering height and exceptional brightness of the clouds in the RGB image signify strong surface heating or convergence leading to vigorous, persistent uplift. This rapid vertical transport of moist air through the deep troposphere allows substantial latent heat release, fueling the massive development characteristic of severe convective storms.\"}, {\"theme\": \"Theme 4: Anomaly & Mismatch\", \"question\": \"Does the satellite imagery indicate a stable, clear, or generally calm weather regime over the observed area?\", \"answer\": \"No, the imagery strongly contradicts the notion of a stable or calm regime. The RGB panel is dominated by deep, turbulent, and highly reflective cumulonimbus clouds, which are unmistakable signatures of extreme atmospheric instability. This intense convective activity suggests vigorous vertical motion, a high potential for heavy rainfall, and associated severe phenomena, indicating a highly active storm system.\"}, {\"theme\": \"Theme 5: Cross-Modal Comparison\", \"question\": \"How does the LST/IR data (right panel) corroborate the visual interpretation of cloud height derived from the reflectivity in the RGB image (left panel)?\", \"answer\": \"The LST/IR image strongly corroborates the interpretation of extremely high cloud tops derived from the RGB image. The massive, bright structures seen in the RGB image, which indicate high reflectivity and vertical extent, correspond to large areas of black in the LST/IR panel. This black coloring signifies cloud tops that are very cold, confirming the exceptional vertical development that penetrates high into the troposphere, a key characteristic of severe convective storms.\"}, {\"theme\": \"Theme 6: Counterfactual Reasoning\", \"question\": \"If the environment surrounding the main convective cells showed clear skies and strong land surface heating, how might that influence the longevity and intensity of the existing storms?\", \"answer\": \"If the surrounding environment were characterized by clear skies and strong land surface heating, the intensity and longevity of the existing storms would likely be enhanced. Strong heating would increase the temperature and moisture contrast near the storm boundaries, generating more buoyant air that could be ingested into the storm system. This continuous supply of energy and moisture would help sustain the deep convection and potentially increase the storm's severity and size.\"}]}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "output_images=\"./seperated\"\n",
    "output_json=\"./stage1_preprocessed_items.json\"\n",
    "# output json sample item\n",
    "\"\"\"\n",
    "    {\n",
    "        \"image\": \"/home/agi592/kse/ClimateToText/data/WeatherQA/WeatherQA_MD_2014-2019/md_image/2018/ttd/md0022_20180112_13_ttd.gif\",\n",
    "        \"annotation\": \"Areas affected...Middle....\",\n",
    "        \"cond_name\": \"wqa:ttd\"\n",
    "    },\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66212e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from PIL import Image, ImageDraw\n",
    "from typing import Dict, Optional, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_full_filename_metadata(filename: str) -> Dict:\n",
    "    \"\"\"\n",
    "    파일 이름의 모든 메타데이터를 파싱하여 딕셔너리로 반환합니다.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    pattern = r'([^_]+)_([^_]+)_(day|night)_coco(\\d+)_(\\d{8})_lh(\\d+)_([-\\d.]+)_([-\\d.]+)_([-\\d.]+)_([-\\d.]+)\\.png'\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        metadata['filename'] = filename\n",
    "        metadata['id'] = match.group(1)\n",
    "        metadata['satellite'] = match.group(2)\n",
    "        metadata['day_night'] = match.group(3)\n",
    "        metadata['coco'] = int(match.group(4))\n",
    "        metadata['utc_yymmddhh'] = match.group(5)\n",
    "        metadata['local_hour_filename'] = int(match.group(6))\n",
    "        metadata['bbox_lat1'] = float(match.group(7))\n",
    "        metadata['bbox_lon1'] = float(match.group(8))\n",
    "        metadata['bbox_lat2'] = float(match.group(9))\n",
    "        metadata['bbox_lon2'] = float(match.group(10))\n",
    "    return metadata\n",
    "\n",
    "def calculate_dot_position(metadata: Dict) -> Tuple[Optional[float], Optional[float], bool]:\n",
    "    \"\"\"\n",
    "    메타데이터(CSV의 lat/lon 및 파일명의 bbox)를 기반으로\n",
    "    128x128 이미지 상의 점의 (x, y) 픽셀 위치를 계산합니다.\n",
    "    \"\"\"\n",
    "    dot_keys = ['lat', 'lon', 'bbox_lat1', 'bbox_lon1', 'bbox_lat2', 'bbox_lon2']\n",
    "    if not all(key in metadata for key in dot_keys):\n",
    "        return None, None, False\n",
    "\n",
    "    try:\n",
    "        lat_target = float(metadata['lat'])\n",
    "        lon_target = float(metadata['lon'])\n",
    "        lat_min = float(metadata['bbox_lat1'])\n",
    "        lon_min = float(metadata['bbox_lon1'])\n",
    "        lat_max = float(metadata['bbox_lat2'])\n",
    "        lon_max = float(metadata['bbox_lon2'])\n",
    "\n",
    "        img_width = 128\n",
    "        img_height = 128\n",
    "        \n",
    "        if (lon_max - lon_min) == 0 or (lat_max - lat_min) == 0:\n",
    "            return None, None, False\n",
    "        else:\n",
    "            lon_percent = (lon_target - lon_min) / (lon_max - lon_min)\n",
    "            pixel_x = lon_percent * (img_width - 1)\n",
    "            \n",
    "            lat_percent_from_top = (lat_max - lat_target) / (lat_max - lat_min)\n",
    "            pixel_y = lat_percent_from_top * (img_height - 1)\n",
    "\n",
    "            if not (0 <= pixel_x < img_width and 0 <= pixel_y < img_height):\n",
    "                return None, None, False\n",
    "            \n",
    "            return pixel_x, pixel_y, True\n",
    "\n",
    "    except (ValueError, TypeError, ZeroDivisionError):\n",
    "        return None, None, False\n",
    "\n",
    "def add_purple_dot_to_image(img: Image.Image, pixel_x: float, pixel_y: float) -> Image.Image:\n",
    "    \"\"\"\n",
    "    이미지에 보라색 점을 추가합니다.\n",
    "    \"\"\"\n",
    "    img = img.convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.ellipse((pixel_x - 2, pixel_y - 2, pixel_x + 2, pixel_y + 2), fill='purple', outline='purple')\n",
    "    return img\n",
    "\n",
    "def combine_images_horizontally(rgb_img: Image.Image, ir_img: Image.Image) -> Image.Image:\n",
    "    \"\"\"\n",
    "    두 이미지를 가로로 합칩니다.\n",
    "    \"\"\"\n",
    "    # 두 이미지의 높이를 맞춤\n",
    "    h = min(rgb_img.height, ir_img.height)\n",
    "    rgb_img = rgb_img.resize((int(rgb_img.width * h / rgb_img.height), h))\n",
    "    ir_img = ir_img.resize((int(ir_img.width * h / ir_img.height), h))\n",
    "    \n",
    "    total_width = rgb_img.width + ir_img.width\n",
    "    combined_img = Image.new('RGB', (total_width, h))\n",
    "    combined_img.paste(rgb_img, (0, 0))\n",
    "    combined_img.paste(ir_img, (rgb_img.width, 0))\n",
    "    \n",
    "    return combined_img\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "os.makedirs(output_images, exist_ok=True)\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "output_items = []\n",
    "\n",
    "# annotation jsonl 파일 읽기\n",
    "print(f\"Processing {annotation}...\")\n",
    "with open(annotation, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "failed_count = 0\n",
    "success_count = 0\n",
    "\n",
    "for line in tqdm(lines, desc=\"Processing annotations\"):\n",
    "    if not line.strip():\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # 필요한 정보 추출\n",
    "        source_filename = data.get('source_filename')\n",
    "        ground_truth = data.get('ground_truth_labels', {})\n",
    "        generated_qas = data.get('generated_qas', [])\n",
    "        \n",
    "        if not source_filename or not generated_qas:\n",
    "            failed_count += 1\n",
    "            continue\n",
    "        \n",
    "        # 파일명에서 메타데이터 파싱\n",
    "        filename_metadata = parse_full_filename_metadata(source_filename)\n",
    "        \n",
    "        # ground_truth와 병합\n",
    "        merged_metadata = {**ground_truth, **filename_metadata}\n",
    "        \n",
    "        # 이미지 경로 구성\n",
    "        rgb_path = os.path.join(rgb_images, source_filename)\n",
    "        ir_path = os.path.join(ir_images, source_filename)\n",
    "        \n",
    "        # 이미지 파일 존재 확인\n",
    "        if not os.path.exists(rgb_path) or not os.path.exists(ir_path):\n",
    "            failed_count += 1\n",
    "            continue\n",
    "        \n",
    "        # 이미지 로드\n",
    "        rgb_img = Image.open(rgb_path)\n",
    "        ir_img = Image.open(ir_path)\n",
    "        \n",
    "        # 점 위치 계산\n",
    "        pixel_x, pixel_y, can_plot_dot = calculate_dot_position(merged_metadata)\n",
    "        \n",
    "        # 두 이미지에 보라색 점 추가\n",
    "        if can_plot_dot:\n",
    "            rgb_img = add_purple_dot_to_image(rgb_img, pixel_x, pixel_y)\n",
    "            ir_img = add_purple_dot_to_image(ir_img, pixel_x, pixel_y)\n",
    "        \n",
    "        # RGB 이미지 저장\n",
    "        rgb_output_path = os.path.join(output_images, f\"rgb_{source_filename}\")\n",
    "        rgb_img.save(rgb_output_path)\n",
    "        \n",
    "        # LST 이미지 저장\n",
    "        lst_output_path = os.path.join(output_images, f\"lst_{source_filename}\")\n",
    "        ir_img.save(lst_output_path)\n",
    "        \n",
    "        # 출력 JSON 아이템 생성 (RGB)\n",
    "        output_item_rgb = {\n",
    "            \"image\": os.path.abspath(rgb_output_path),\n",
    "            \"annotation\": generated_qas[0]['answer'],\n",
    "            \"cond_name\": \"modis:rgb\"\n",
    "        }\n",
    "        output_items.append(output_item_rgb)\n",
    "        \n",
    "        # 출력 JSON 아이템 생성 (LST)\n",
    "        output_item_lst = {\n",
    "            \"image\": os.path.abspath(lst_output_path),\n",
    "            \"annotation\": generated_qas[0]['answer'],\n",
    "            \"cond_name\": \"modis:lst\"\n",
    "        }\n",
    "        output_items.append(output_item_lst)\n",
    "        success_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing line: {e}\")\n",
    "        failed_count += 1\n",
    "        continue\n",
    "\n",
    "# 출력 JSON 파일 저장\n",
    "with open(output_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_items, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nProcessing complete!\")\n",
    "print(f\"Success: {success_count} items\")\n",
    "print(f\"Failed: {failed_count} items\")\n",
    "print(f\"Output JSON: {output_json}\")\n",
    "print(f\"Output images directory: {output_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e528716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all in ./rgb and ./ir to seperated_all\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from PIL import Image, ImageDraw\n",
    "from typing import Dict, Optional, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 설정\n",
    "annotation_file = \"./gee_weather_ground_truth_balanced.csv\"\n",
    "# id,time,lat,lon,coco,local_hour,temp,dwpt,rhum,prcp,snow,wdir,wspd,wpgt,pres,tsun\n",
    "# 71917,2023-11-21 07:00:00,79.99,-85.81,1,1,-23.0,-26.0,76.0,0.0,,290.0,20.5,,1002.3,\n",
    "\n",
    "# KFLY0_terra_day_coco3_23072517_lh10_38.353755_-106.820302_42.966368_-100.739783.png\n",
    "# pk: {id, yymmddhh, lh{localhour}}\n",
    "rgb_input_dir = \"./rgb\"\n",
    "ir_input_dir = \"./ir\"\n",
    "output_dir = \"./seperated_all\"\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def parse_full_filename_metadata(filename: str) -> Dict:\n",
    "    \"\"\"파일 이름의 모든 메타데이터를 파싱하여 딕셔너리로 반환합니다.\"\"\"\n",
    "    metadata = {}\n",
    "    pattern = r'([^_]+)_([^_]+)_(day|night)_coco(\\d+)_(\\d{8})_lh(\\d+)_([-\\d.]+)_([-\\d.]+)_([-\\d.]+)_([-\\d.]+)\\.png'\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        metadata['filename'] = filename\n",
    "        metadata['id'] = match.group(1)\n",
    "        metadata['satellite'] = match.group(2)\n",
    "        metadata['day_night'] = match.group(3)\n",
    "        metadata['coco'] = int(match.group(4))\n",
    "        metadata['utc_yymmddhh'] = match.group(5)\n",
    "        metadata['local_hour_filename'] = int(match.group(6))\n",
    "        metadata['bbox_lat1'] = float(match.group(7))\n",
    "        metadata['bbox_lon1'] = float(match.group(8))\n",
    "        metadata['bbox_lat2'] = float(match.group(9))\n",
    "        metadata['bbox_lon2'] = float(match.group(10))\n",
    "    return metadata\n",
    "\n",
    "def calculate_dot_position(metadata: Dict) -> Tuple[Optional[float], Optional[float], bool]:\n",
    "    \"\"\"메타데이터를 기반으로 128x128 이미지 상의 점의 (x, y) 픽셀 위치를 계산합니다.\"\"\"\n",
    "    dot_keys = ['lat', 'lon', 'bbox_lat1', 'bbox_lon1', 'bbox_lat2', 'bbox_lon2']\n",
    "    if not all(key in metadata for key in dot_keys):\n",
    "        return None, None, False\n",
    "\n",
    "    try:\n",
    "        lat_target = float(metadata['lat'])\n",
    "        lon_target = float(metadata['lon'])\n",
    "        lat_min = float(metadata['bbox_lat1'])\n",
    "        lon_min = float(metadata['bbox_lon1'])\n",
    "        lat_max = float(metadata['bbox_lat2'])\n",
    "        lon_max = float(metadata['bbox_lon2'])\n",
    "\n",
    "        img_width = 128\n",
    "        img_height = 128\n",
    "        \n",
    "        if (lon_max - lon_min) == 0 or (lat_max - lat_min) == 0:\n",
    "            return None, None, False\n",
    "        else:\n",
    "            lon_percent = (lon_target - lon_min) / (lon_max - lon_min)\n",
    "            pixel_x = lon_percent * (img_width - 1)\n",
    "            \n",
    "            lat_percent_from_top = (lat_max - lat_target) / (lat_max - lat_min)\n",
    "            pixel_y = lat_percent_from_top * (img_height - 1)\n",
    "\n",
    "            if not (0 <= pixel_x < img_width and 0 <= pixel_y < img_height):\n",
    "                return None, None, False\n",
    "            \n",
    "            return pixel_x, pixel_y, True\n",
    "\n",
    "    except (ValueError, TypeError, ZeroDivisionError):\n",
    "        return None, None, False\n",
    "\n",
    "def add_purple_dot_to_image(img: Image.Image, pixel_x: float, pixel_y: float) -> Image.Image:\n",
    "    \"\"\"이미지에 보라색 점을 추가합니다.\"\"\"\n",
    "    img = img.convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.ellipse((pixel_x - 2, pixel_y - 2, pixel_x + 2, pixel_y + 2), fill='purple', outline='purple')\n",
    "    return img\n",
    "\n",
    "def make_composite_key(station_id: str, yymmddhh: str, local_hour: int) -> str:\n",
    "    \"\"\"복합 키 생성: {id}_{yymmddhh}_{lh}\"\"\"\n",
    "    return f\"{station_id}_{yymmddhh}_{local_hour}\"\n",
    "\n",
    "# CSV 파일에서 메타데이터 매핑 생성\n",
    "# 복합 키: {id, yymmddhh, local_hour} -> {lat, lon, ...}\n",
    "composite_key_to_metadata = {}\n",
    "print(f\"Loading metadata from {annotation_file}...\")\n",
    "with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        station_id = row.get('id')\n",
    "        time_str = row.get('time')  # \"2023-11-21 07:00:00\"\n",
    "        local_hour_str = row.get('local_hour')\n",
    "        \n",
    "        if station_id and time_str and local_hour_str:\n",
    "            try:\n",
    "                # time에서 yymmddhh 추출: \"2023-11-21 07:00:00\" -> \"23112107\"\n",
    "                # time 형식: YYYY-MM-DD HH:MM:SS\n",
    "                parts = time_str.split(' ')\n",
    "                date_part = parts[0]  # \"2023-11-21\"\n",
    "                time_part = parts[1].split(':')[0]  # \"07\"\n",
    "                \n",
    "                year, month, day = date_part.split('-')\n",
    "                yy = year[2:]  # \"23\"\n",
    "                mm = month  # \"11\"\n",
    "                dd = day  # \"21\"\n",
    "                hh = time_part  # \"07\"\n",
    "                \n",
    "                yymmddhh = f\"{yy}{mm}{dd}{hh}\"\n",
    "                local_hour = int(local_hour_str)\n",
    "                \n",
    "                composite_key = make_composite_key(station_id, yymmddhh, local_hour)\n",
    "                composite_key_to_metadata[composite_key] = row\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "print(f\"Loaded metadata for {len(composite_key_to_metadata)} records\")\n",
    "\n",
    "# 파일명에서 복합 키를 추출하고 CSV 데이터와 매칭\n",
    "def get_metadata_for_file(filename: str) -> Optional[Dict]:\n",
    "    \"\"\"파일명에서 복합 키를 추출하고 CSV 데이터와 병합합니다.\"\"\"\n",
    "    filename_metadata = parse_full_filename_metadata(filename)\n",
    "    if not filename_metadata:\n",
    "        return None\n",
    "    \n",
    "    station_id = filename_metadata.get('id')\n",
    "    yymmddhh = filename_metadata.get('utc_yymmddhh')\n",
    "    local_hour = filename_metadata.get('local_hour_filename')\n",
    "    \n",
    "    if station_id and yymmddhh and local_hour is not None:\n",
    "        composite_key = make_composite_key(station_id, yymmddhh, local_hour)\n",
    "        \n",
    "        if composite_key in composite_key_to_metadata:\n",
    "            # CSV 데이터와 파일명 메타데이터 병합\n",
    "            csv_data = composite_key_to_metadata[composite_key]\n",
    "            merged = {**csv_data, **filename_metadata}\n",
    "            return merged\n",
    "    \n",
    "    return None\n",
    "\n",
    "# RGB 이미지 처리\n",
    "print(\"\\nProcessing RGB images...\")\n",
    "rgb_files = [f for f in os.listdir(rgb_input_dir) if f.endswith('.png')]\n",
    "success_rgb = 0\n",
    "failed_rgb = 0\n",
    "dot_added_rgb = 0\n",
    "no_metadata_rgb = 0\n",
    "\n",
    "for filename in tqdm(rgb_files, desc=\"RGB images\"):\n",
    "    try:\n",
    "        input_path = os.path.join(rgb_input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, f\"rgb_{filename}\")\n",
    "        \n",
    "        img = Image.open(input_path)\n",
    "        \n",
    "        # 메타데이터가 있으면 보라색 점 추가\n",
    "        metadata = get_metadata_for_file(filename)\n",
    "        if metadata:\n",
    "            pixel_x, pixel_y, can_plot = calculate_dot_position(metadata)\n",
    "            if can_plot:\n",
    "                img = add_purple_dot_to_image(img, pixel_x, pixel_y)\n",
    "                dot_added_rgb += 1\n",
    "        else:\n",
    "            no_metadata_rgb += 1\n",
    "        \n",
    "        img.save(output_path)\n",
    "        success_rgb += 1\n",
    "    except Exception as e:\n",
    "        failed_rgb += 1\n",
    "        continue\n",
    "\n",
    "print(f\"RGB - Success: {success_rgb}, Failed: {failed_rgb}, Dots added: {dot_added_rgb}, No metadata: {no_metadata_rgb}\")\n",
    "\n",
    "# IR 이미지 처리\n",
    "print(\"\\nProcessing IR images...\")\n",
    "ir_files = [f for f in os.listdir(ir_input_dir) if f.endswith('.png')]\n",
    "success_ir = 0\n",
    "failed_ir = 0\n",
    "dot_added_ir = 0\n",
    "no_metadata_ir = 0\n",
    "\n",
    "for filename in tqdm(ir_files, desc=\"IR images\"):\n",
    "    try:\n",
    "        input_path = os.path.join(ir_input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, f\"lst_{filename}\")\n",
    "        \n",
    "        img = Image.open(input_path)\n",
    "        \n",
    "        # 메타데이터가 있으면 보라색 점 추가\n",
    "        metadata = get_metadata_for_file(filename)\n",
    "        if metadata:\n",
    "            pixel_x, pixel_y, can_plot = calculate_dot_position(metadata)\n",
    "            if can_plot:\n",
    "                img = add_purple_dot_to_image(img, pixel_x, pixel_y)\n",
    "                dot_added_ir += 1\n",
    "        else:\n",
    "            no_metadata_ir += 1\n",
    "        \n",
    "        img.save(output_path)\n",
    "        success_ir += 1\n",
    "    except Exception as e:\n",
    "        failed_ir += 1\n",
    "        continue\n",
    "\n",
    "print(f\"IR - Success: {success_ir}, Failed: {failed_ir}, Dots added: {dot_added_ir}, No metadata: {no_metadata_ir}\")\n",
    "print(f\"\\nAll images saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 1000 rgb images and 1000 lst images from ./seperated_all and save to ./seperated_eval\n",
    "# Note: that images SHOULD NOT be in ./seperated\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "source_dir = \"./seperated_all\"\n",
    "eval_dir = \"./seperated_eval\"\n",
    "train_dir = \"./seperated\"\n",
    "num_samples_per_type = 1000\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "# seperated_all의 모든 이미지 파일 가져오기\n",
    "all_images = [f for f in os.listdir(source_dir) if f.endswith('.png')]\n",
    "print(f\"Total images in {source_dir}: {len(all_images)}\")\n",
    "\n",
    "# RGB와 LST 이미지 분리\n",
    "rgb_images = [f for f in all_images if f.startswith('rgb_')]\n",
    "lst_images = [f for f in all_images if f.startswith('lst_')]\n",
    "print(f\"RGB images: {len(rgb_images)}, LST images: {len(lst_images)}\")\n",
    "\n",
    "# seperated에 있는 이미지 파일명 가져오기 (제외할 목록)\n",
    "if os.path.exists(train_dir):\n",
    "    train_images = set(os.listdir(train_dir))\n",
    "    print(f\"Images in {train_dir} (to exclude): {len(train_images)}\")\n",
    "else:\n",
    "    train_images = set()\n",
    "    print(f\"{train_dir} does not exist, no images to exclude\")\n",
    "\n",
    "# seperated_all에만 있는 이미지 필터링\n",
    "available_rgb = [img for img in rgb_images if img not in train_images]\n",
    "available_lst = [img for img in lst_images if img not in train_images]\n",
    "print(f\"Available RGB images for eval: {len(available_rgb)}\")\n",
    "print(f\"Available LST images for eval: {len(available_lst)}\")\n",
    "\n",
    "# 샘플링할 개수 결정\n",
    "actual_rgb_samples = min(num_samples_per_type, len(available_rgb))\n",
    "actual_lst_samples = min(num_samples_per_type, len(available_lst))\n",
    "print(f\"Sampling {actual_rgb_samples} RGB images and {actual_lst_samples} LST images\")\n",
    "\n",
    "# 랜덤 샘플링\n",
    "random.seed(42)  # 재현성을 위한 시드 설정\n",
    "selected_rgb = random.sample(available_rgb, actual_rgb_samples)\n",
    "selected_lst = random.sample(available_lst, actual_lst_samples)\n",
    "\n",
    "# RGB 이미지 복사\n",
    "print(f\"\\nCopying RGB images to {eval_dir}...\")\n",
    "for img_name in tqdm(selected_rgb, desc=\"Copying RGB images\"):\n",
    "    src_path = os.path.join(source_dir, img_name)\n",
    "    dst_path = os.path.join(eval_dir, img_name)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# LST 이미지 복사\n",
    "print(f\"\\nCopying LST images to {eval_dir}...\")\n",
    "for img_name in tqdm(selected_lst, desc=\"Copying LST images\"):\n",
    "    src_path = os.path.join(source_dir, img_name)\n",
    "    dst_path = os.path.join(eval_dir, img_name)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "\n",
    "print(f\"\\nSuccessfully copied {len(selected_rgb)} RGB and {len(selected_lst)} LST images to {eval_dir}\")\n",
    "print(f\"Total: {len(selected_rgb) + len(selected_lst)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 100 rgb and 100 lst images and construct jsonl file with below format\n",
    "\"\"\"\n",
    "{\n",
    "    \"image\": \"/home/agi592/yjju/EarthData/seperated/rgb_KAIK0_aqua_day_coco3_23090819_lh14_32.924186_-82.100136_34.077339_-80.717257.png\",\n",
    "    \"annotation\": \"\",\n",
    "    \"cond_name\": \"modis:rgb\"\n",
    "},\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "source_dir = \"./seperated_eval\"\n",
    "output_jsonl = \"./stage1_preprocessed_items_sep_eval.json\"\n",
    "num_samples_per_type = 100\n",
    "\n",
    "# seperated_eval의 모든 이미지 파일 가져오기\n",
    "all_images = [f for f in os.listdir(source_dir) if f.endswith('.png')]\n",
    "print(f\"Total images in {source_dir}: {len(all_images)}\")\n",
    "\n",
    "# RGB와 LST 이미지 분리\n",
    "rgb_images = [f for f in all_images if f.startswith('rgb_')]\n",
    "lst_images = [f for f in all_images if f.startswith('lst_')]\n",
    "print(f\"RGB images: {len(rgb_images)}, LST images: {len(lst_images)}\")\n",
    "\n",
    "# 샘플링할 개수 결정\n",
    "actual_rgb_samples = min(num_samples_per_type, len(rgb_images))\n",
    "actual_lst_samples = min(num_samples_per_type, len(lst_images))\n",
    "print(f\"Sampling {actual_rgb_samples} RGB images and {actual_lst_samples} LST images\")\n",
    "\n",
    "# 랜덤 샘플링\n",
    "random.seed(42)  # 재현성을 위한 시드 설정\n",
    "selected_rgb = random.sample(rgb_images, actual_rgb_samples)\n",
    "selected_lst = random.sample(lst_images, actual_lst_samples)\n",
    "\n",
    "# JSON 아이템 생성\n",
    "output_items = []\n",
    "\n",
    "# RGB 이미지 아이템 생성\n",
    "for img_name in selected_rgb:\n",
    "    img_path = os.path.abspath(os.path.join(source_dir, img_name))\n",
    "    item = {\n",
    "        \"image\": img_path,\n",
    "        \"annotation\": \"\",\n",
    "        \"cond_name\": \"modis:rgb\"\n",
    "    }\n",
    "    output_items.append(item)\n",
    "\n",
    "# LST 이미지 아이템 생성\n",
    "for img_name in selected_lst:\n",
    "    img_path = os.path.abspath(os.path.join(source_dir, img_name))\n",
    "    item = {\n",
    "        \"image\": img_path,\n",
    "        \"annotation\": \"\",\n",
    "        \"cond_name\": \"modis:lst\"\n",
    "    }\n",
    "    output_items.append(item)\n",
    "\n",
    "# JSON 파일로 저장\n",
    "with open(output_jsonl, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_items, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nGenerated {len(output_items)} items ({len(selected_rgb)} RGB + {len(selected_lst)} LST)\")\n",
    "print(f\"Output saved to: {output_jsonl}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
